{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arpdm/predictive-maintenance-platform/blob/main/PdM_NASA_ENGINES.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wzGRgs7JQqds",
        "outputId": "9f691419-d75a-43b7-d4e9-222ed438519a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# Colab data file preparation\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount(\"/content/drive\")\n",
        "\n",
        "!cp drive/MyDrive/Predictive_Maintenence_Fault_Detection/predictive-maintenance-platform/data_processor.py .\n",
        "!cp drive/MyDrive/Predictive_Maintenence_Fault_Detection/predictive-maintenance-platform/visualizer_analyzer.py .\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Rwp9tyDxtYor"
      },
      "outputs": [],
      "source": [
        "from tabnanny import verbose\n",
        "from data_processor import DataProcessor\n",
        "from visualizer_analyzer import DataAV\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "# Load all datasets\n",
        "DS_001 = \"/content/drive/MyDrive/Predictive_Maintenence_Fault_Detection/data_set/N-CMAPSS_DS01-005.h5\"\n",
        "DS_002 = \"/content/drive/MyDrive/Predictive_Maintenence_Fault_Detection/data_set/N-CMAPSS_DS02-006.h5\"\n",
        "DS_003 = \"/content/drive/MyDrive/Predictive_Maintenence_Fault_Detection/data_set/N-CMAPSS_DS03-012.h5\"\n",
        "DS_004 = \"/content/drive/MyDrive/Predictive_Maintenence_Fault_Detection/data_set/N-CMAPSS_DS04.h5\"\n",
        "DS_005 = \"/content/drive/MyDrive/Predictive_Maintenence_Fault_Detection/data_set/N-CMAPSS_DS05.h5\"\n",
        "DS_006 = \"/content/drive/MyDrive/Predictive_Maintenence_Fault_Detection/data_set/N-CMAPSS_DS06.h5\"\n",
        "DS_007 = \"/content/drive/MyDrive/Predictive_Maintenence_Fault_Detection/data_set/N-CMAPSS_DS07.h5\"\n",
        "DS_008 = \"/content/drive/MyDrive/Predictive_Maintenence_Fault_Detection/data_set/N-CMAPSS_DS08a-009.h5\"\n",
        "DS_009 = \"/content/drive/MyDrive/Predictive_Maintenence_Fault_Detection/data_set/N-CMAPSS_DS08c-008.h5\"\n",
        "DS_010 = \"/content/drive/MyDrive/Predictive_Maintenence_Fault_Detection/data_set/N-CMAPSS_DS08d-010.h5\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DdRX8ShGxYUf"
      },
      "outputs": [],
      "source": [
        "# Load data set and prepare data frames\n",
        "pros = DataProcessor()\n",
        "pros.load_hdf5_to_numpy_arr(DS_004)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UIaEEsE8xiHh"
      },
      "outputs": [],
      "source": [
        "# Create a visualizer class. This is useful for understanding the data we work with\n",
        "# it will determine feature extraction and model architecture to some extend\n",
        "vs_an = DataAV(pros.df_aux,pros.df_x_s,pros.x_s_var_names,pros.df_w,pros.df_t,pros.t_var_names,pros.w_var_names,pros.df_ts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Axh6tnn3Y1xD"
      },
      "outputs": [],
      "source": [
        "pros.x_s_dev"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pT-0Jxt-xxLn"
      },
      "outputs": [],
      "source": [
        "# Generate all visualization graphs and plots necessary for understanding data.\n",
        "vs_an.get_engine_units_in_dataset()\n",
        "vs_an.plot_flight_classes()\n",
        "vs_an.show_engine_health_parameter_stats()\n",
        "vs_an.generate_engine_health_parameter_graphs()\n",
        "vs_an.generate_hpt_eff_over_cycles_all_engines()\n",
        "vs_an.generate_sensor_readings_graphs_single_unit(1)\n",
        "vs_an.generate_sensor_readings_graphs_single_unit_single_cycle(1, 2)\n",
        "vs_an.plot_health_states_for_all_engines()\n",
        "vs_an.generate_flight_profle_single_unit_single_cycle(1, 2)\n",
        "vs_an.generate_flight_envelope()\n",
        "vs_an.generate_kde_estimations_of_flight_profile()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "XIBzs0CZ00SG"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Genearate the tf dataset with proper dimensionality and shape given input parameters.\n",
        "This dataset will split into training and validation subsets.\n",
        "\"\"\"\n",
        "\n",
        "window = 48\n",
        "horizon = 1\n",
        "train_split = 6377452\n",
        "batch_size = 256\n",
        "buffer_size = 150\n",
        "\n",
        "x_train, y_train = pros.custom_ts_multi_data_prep(pros.w, pros.y_rul, 0, train_split, window, horizon)\n",
        "x_vali, y_vali = pros.custom_ts_multi_data_prep(pros.w, pros.y_rul, train_split, None, window, horizon)\n",
        "\n",
        "train_data = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
        "train_data = train_data.cache().shuffle(buffer_size).batch(batch_size).repeat()\n",
        "\n",
        "val_data = tf.data.Dataset.from_tensor_slices((x_vali, y_vali))\n",
        "val_data = val_data.batch(batch_size).repeat()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I0j7cBtH1KJB"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Build the DNN model with its layers that will be used for RUL preditcions.\n",
        "\"\"\"\n",
        "\n",
        "model = tf.keras.models.Sequential(\n",
        "    [\n",
        "        tf.keras.layers.Bidirectional(\n",
        "            tf.keras.layers.LSTM(200, return_sequences=True), input_shape=x_train.shape[-2:]\n",
        "        ),\n",
        "        tf.keras.layers.Dense(20, activation=\"tanh\"),\n",
        "        tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(150)),\n",
        "        tf.keras.layers.Dense(20, activation=\"tanh\"),\n",
        "        tf.keras.layers.Dense(20, activation=\"tanh\"),\n",
        "        tf.keras.layers.Dropout(0.25),\n",
        "        tf.keras.layers.Dense(1),\n",
        "    ]\n",
        ")\n",
        "\n",
        "model.compile(optimizer=\"sgd\", loss=\"mae\")\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nH0wEpEhRORh"
      },
      "outputs": [],
      "source": [
        "# Model - 2 That uses Convolution, LSTM, and Dense\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Conv1D(filters=64, kernel_size=3,\n",
        "                      strides=1,\n",
        "                      activation=\"relu\",\n",
        "                      padding='causal',\n",
        "                      input_shape= x_train.shape[-2:]),\n",
        "  tf.keras.layers.LSTM(64, return_sequences=True),\n",
        "  tf.keras.layers.LSTM(64),\n",
        "  tf.keras.layers.Dense(30, activation=\"relu\"),\n",
        "  tf.keras.layers.Dense(10, activation=\"sigmoid\"),\n",
        "  tf.keras.layers.Dense(1),\n",
        "  tf.keras.layers.Lambda(lambda x: x * 400)\n",
        "])\n",
        "\n",
        "model.compile(optimizer=\"adam\", loss=\"mae\", metrics=['accuracy'])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yPT9C8PB1R3W"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Train the generate model based on provided epochs and steps.\n",
        "This function will also automatically generate the plot for loss history.\n",
        "\"\"\"\n",
        "\n",
        "epochs = 60\n",
        "steps = 100\n",
        "validation_steps = 50\n",
        "verbose = 1\n",
        "\n",
        "tf.keras.backend.clear_session()\n",
        "\n",
        "history = model.fit(\n",
        "    x=train_data, epochs=epochs, steps_per_epoch=steps, validation_data=val_data, validation_steps=validation_steps, verbose=verbose\n",
        ")\n",
        "\n",
        "vs_an.plot_training_results_history(history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "piMr4beq4h4J"
      },
      "outputs": [],
      "source": [
        "y_pred = model.predict(x_vali)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5MXhZAS1Ju-2"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(16,9))\n",
        "plt.plot( list(y_vali.reshape(-1)))\n",
        "plt.plot( list(y_pred.reshape(-1)))\n",
        "plt.title(\"Actual vs Predicted\")\n",
        "plt.ylabel(\"Traffic volume\")\n",
        "plt.legend(('Actual','predicted'))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZyI4_CnXEKkC"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "5_qrtGTGIIQk"
      },
      "outputs": [],
      "source": [
        "test_mae_loss = np.mean(np.abs(y_pred.reshape(1,-1) - y_vali.reshape(1,-1)), axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rf-FephOKw5U"
      },
      "outputs": [],
      "source": [
        "test_mae_loss"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "include_colab_link": true,
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3.10.6 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.7"
    },
    "vscode": {
      "interpreter": {
        "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
