{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/arpdm/predictive-maintenance-platform/blob/main/PdM_NASA_ENGINES_003.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount(\"/content/drive/\")\n",
    "\n",
    "!cp drive/MyDrive/PdM/predictive-maintenance-platform/engine_data.py .\n",
    "!cp drive/MyDrive/PdM/predictive-maintenance-platform/plot_util.py .\n",
    "!cp drive/MyDrive/PdM/predictive-maintenance-platform/mark_001_model.py .\n",
    "!cp drive/MyDrive/PdM/predictive-maintenance-platform/pcoe_engine_data_visualizer.py ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install tensorflow-addons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "from engine_data import EngineData\n",
    "from pcoe_engine_data_visualizer import PcoeEngingeVis\n",
    "from plot_util import PlotUtil\n",
    "from mark_001_model import Mark001Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all datasets\n",
    "BASE_PATH = \"/content/drive/MyDrive/PdM/data_set/\"\n",
    "\n",
    "DS_001 = BASE_PATH + \"N-CMAPSS_DS01-005.h5\"\n",
    "DS_002 = BASE_PATH + \"N-CMAPSS_DS02-006.h5\"\n",
    "DS_003 = BASE_PATH + \"N-CMAPSS_DS03-012.h5\"\n",
    "DS_004 = BASE_PATH + \"N-CMAPSS_DS04.h5\"\n",
    "DS_005 = BASE_PATH + \"N-CMAPSS_DS05.h5\"\n",
    "DS_006 = BASE_PATH + \"N-CMAPSS_DS06.h5\"\n",
    "DS_007 = BASE_PATH + \"N-CMAPSS_DS07.h5\"\n",
    "DS_008 = BASE_PATH + \"N-CMAPSS_DS08a-009.h5\"\n",
    "DS_009 = BASE_PATH + \"N-CMAPSS_DS08c-008.h5\"\n",
    "DS_010 = BASE_PATH + \"N-CMAPSS_DS08d-010.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data set and prepare data frames\n",
    "ed = EngineData()\n",
    "pcoe_enging_vis = PcoeEngingeVis(ed)\n",
    "plot_util = PlotUtil()\n",
    "mark_001 = Mark001Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset load block\n",
    "ed.load_hdf5_to_numpy_arr(DS_001)\n",
    "ed.df_x_s_train = ed.add_labels_to_dataset(ed.df_x_s_train)\n",
    "ed.df_x_s_train = ed.normalize_dataset(ed.df_x_s_train)\n",
    "ed.df_x_s_test = ed.add_labels_to_dataset(ed.df_x_s_test)\n",
    "ed.df_x_s_test = ed.normalize_dataset(ed.df_x_s_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 003\n",
    "\n",
    "**Experiment goal:** Tune the Learning Rate\n",
    "\n",
    "**Approach:** We will use logarithmic scale to generate random learning rates and train/validate/test with each learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model build block\n",
    "window = 50\n",
    "batch_size = 256\n",
    "epochs = 40\n",
    "steps = 100\n",
    "patience_epoch = 10\n",
    "data_path = \"/content/drive/MyDrive/PdM/model_generated_data\"\n",
    "features = ed.df_x_s_train.columns.drop([\"RUL\", \"label1\", \"label2\", \"cycle\", \"id\"]).size\n",
    "\n",
    "def train(learning_rate):\n",
    "    \n",
    "    # Hyperparameters required for ADAM Optimizer\n",
    "    adam_params ={\n",
    "        \"learning_rate\": learning_rate,\n",
    "        \"beta_1\": 0.9,\n",
    "        \"beta_2\": 0.999,\n",
    "        \"epsilon\": 1e-8,\n",
    "    }\n",
    "\n",
    "    model_mark_001 = mark_001.create_binary_classifier_model(window, \n",
    "                                                            features, \n",
    "                                                            units_first_layer = 100, \n",
    "                                                            units_second_layer= 50,\n",
    "                                                            dropout_rate= 0.2,\n",
    "                                                            optimizer_hyperparams = adam_params,\n",
    "                                                            adam_w_enabled=False)\n",
    "    \n",
    "    for engine_unit in np.unique(ed.df_aux_train[\"unit\"]):\n",
    "        ## Training Block\n",
    "        single_engine_train = ed.generate_data_frame_for_specific_engine(ed.df_x_s_train, engine_unit)\n",
    "        x_train, y_train = ed.generate_x_y_model_inputs(single_engine_train, window=window)\n",
    "\n",
    "        mark_001_history = mark_001.fit_model(x_train, y_train, epochs, steps, batch_size, patience_epoch)\n",
    "        plot_util.generate_training_history_accuracy_and_loss_plot(mark_001_history, data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    for engine_unit in np.unique(ed.df_aux_test[\"unit\"]):\n",
    "        ## Test Block\n",
    "        print(\"========================================================================================\")\n",
    "        single_engine_test = ed.generate_data_frame_for_specific_engine(ed.df_x_s_test, engine_unit)\n",
    "        x_test, y_test = ed.generate_x_y_model_inputs(single_engine_test, window = window)\n",
    "\n",
    "        (y_pred,y_true, cm) = mark_001.test_model(x_test, y_test)\n",
    "        print(f\"Y_Pred Failure Cycle: { np.where(y_pred==1)[0][0]}\")           \n",
    "        print(f\"Y_Ture Failure Cycle: { np.where(y_true==1)[0][0]}\")      \n",
    "        #plot_util.generate_heat_map(cm)\n",
    "        cm.head()\n",
    "        #plot_util.generate_predicted_vs_true_plot(y_true, y_pred, \"About To Fail\")\n",
    "        #plot_util.generate_about_to_fail_graphs(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXP 03\n",
    "count = 0\n",
    "for r in learning_rates:\n",
    "    count = count + 1\n",
    "    print(f\"RUN {count} --- Learning Rate: {r}\")\n",
    "    train(r)\n",
    "    test()\n",
    "    time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction Dataset\n",
    "ed_predict.load_hdf5_to_numpy_arr(DS_002)\n",
    "ed_predict.df_x_s_train = ed_predict.add_labels_to_dataset(ed.df_x_s_train)\n",
    "ed_predict.df_x_s_train = ed_predict.normalize_dataset(ed.df_x_s_train)\n",
    "ed_predict.df_x_s_test = ed_predict.add_labels_to_dataset(ed.df_x_s_test)\n",
    "ed_predict.df_x_s_test = ed_predict.normalize_dataset(ed.df_x_s_test)\n",
    "\n",
    "for engine_unit in np.unique(ed_predict.df_aux_test[\"unit\"]):\n",
    "    ## Test Block\n",
    "    print(\"========================================================================================\")\n",
    "    single_engine_test = ed_predict.generate_data_frame_for_specific_engine(ed_predict.df_x_s_test, engine_unit)\n",
    "    x_test, y_test = ed_predict.generate_x_y_model_inputs(single_engine_test, window = window)\n",
    "\n",
    "    (y_pred,y_true, cm) = mark_001.test_model(x_test, y_test)\n",
    "    cm.head()\n",
    "\n",
    "    print(f\"Y_Pred Failure Cycle: { np.where(y_pred==1)[0][0]}\")           \n",
    "    print(f\"Y_Ture Failure Cycle: { np.where(y_true==1)[0][0]}\")     "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1be489e4256ebfa0a27a044897bf0efe441c8e767b49ff8728c46fcf16246479"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
